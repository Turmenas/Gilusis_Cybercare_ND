{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SETUP & LIBRARIES"
      ],
      "metadata": {
        "id": "wb4xatpIMdLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9az6V_VE7NC",
        "outputId": "85a76c05-fe28-40f1-9554-5312ec2f9607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ System Initialized: Google Gemini Connected.\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade google-generativeai pandas scikit-learn\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import uuid\n",
        "import datetime\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. Setup API\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "    # Using the standard flash model\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    print(\"‚úÖ System Initialized: Google Gemini Connected.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå CRITICAL SETUP ERROR: {e}\")\n",
        "    print(\"Please set 'GOOGLE_API_KEY' in the Colab Secrets (Key icon on the left).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA INFRASTRUCTURE"
      ],
      "metadata": {
        "id": "WJebpfNNMlys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlu_service(message: str):\n",
        "    \"\"\"\n",
        "    Robust NLU that handles JSON errors.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this support message: \"{message}\"\n",
        "\n",
        "    Return a valid JSON object with keys:\n",
        "    - \"intent\": [\"technical\", \"billing\", \"account\", \"human_escalate\", \"greeting\"]\n",
        "    - \"confidence\": float (0.0 to 1.0)\n",
        "    - \"escalate_reason\": string (if intent is human_escalate)\n",
        "\n",
        "    Escalate ONLY for threats, lawsuits, or explicit requests for a human.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        text = response.text\n",
        "\n",
        "        # Smart JSON Extraction (Finds { ... })\n",
        "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
        "        if match:\n",
        "            return json.loads(match.group(0))\n",
        "        else:\n",
        "            raise ValueError(\"No JSON found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback: Treat as technical so we try to answer it first\n",
        "        return {\"intent\": \"technical\", \"confidence\": 0.5, \"escalate_reason\": \"\"}\n",
        "\n",
        "def response_generator(user_text, nlu_data, context_docs, history_text):\n",
        "    system_prompt = f\"\"\"\n",
        "    You are CyberCare AI.\n",
        "\n",
        "    CONTEXT FROM DATABASE:\n",
        "    {context_docs if context_docs else \"No specific database match.\"}\n",
        "\n",
        "    USER INTENT: {nlu_data.get('intent')}\n",
        "    HISTORY: {history_text}\n",
        "    CURRENT MESSAGE: \"{user_text}\"\n",
        "\n",
        "    Instructions:\n",
        "    1. If 'CONTEXT FROM DATABASE' has a fix, USE IT and paraphrase politely.\n",
        "    2. If no context, provide general helpful advice.\n",
        "    3. Be concise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return model.generate_content(system_prompt).text\n",
        "    except:\n",
        "        return \"I am currently overloaded. Please try again in a moment.\"\n"
      ],
      "metadata": {
        "id": "kMQuQVdtF_8Y"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNOWLEDGE RETRIEVER"
      ],
      "metadata": {
        "id": "39sB3p3EMsZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeRetriever:\n",
        "    \"\"\"\n",
        "    Hybrid Retriever:\n",
        "    - Loads 'QnA.json' for specific NordVPN context (High Priority).\n",
        "    - Loads 'tech_support_dataset.csv' for general tech support training (Low Priority).\n",
        "    - Uses TF-IDF to find the best match across both datasets.\n",
        "    \"\"\"\n",
        "    def __init__(self, json_path=None, csv_path=None):\n",
        "        self.df = pd.DataFrame(columns=[\"question\", \"answer\"])\n",
        "\n",
        "        # 1. Load Specific Context (JSON)\n",
        "        if json_path:\n",
        "            try:\n",
        "                with open(json_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                # Check structure: {\"support\": [...]}\n",
        "                if \"support\" in data:\n",
        "                    json_df = pd.DataFrame(data['support'])\n",
        "                    # Ensure columns are named consistently\n",
        "                    json_df = json_df.rename(columns={\"question\": \"question\", \"answer\": \"answer\"})\n",
        "                    self.df = pd.concat([self.df, json_df], ignore_index=True)\n",
        "                    print(f\"‚úÖ Knowledge Base: Loaded {len(json_df)} specific NordVPN rules from {json_path}.\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è JSON format error: Key 'support' not found.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"‚ö†Ô∏è Specific Context file '{json_path}' not found.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading JSON: {e}\")\n",
        "\n",
        "        # 2. Load General Training (CSV)\n",
        "        if csv_path:\n",
        "            try:\n",
        "                csv_df = pd.read_csv(csv_path, on_bad_lines='skip')\n",
        "\n",
        "                # Map CSV columns to 'question' and 'answer'\n",
        "                # We prioritize 'Customer_Issue' and 'Tech_Response' based on your previous file\n",
        "                q_col = 'Customer_Issue' if 'Customer_Issue' in csv_df.columns else csv_df.columns[0]\n",
        "                a_col = 'Tech_Response' if 'Tech_Response' in csv_df.columns else csv_df.columns[1]\n",
        "\n",
        "                # Normalize and Append\n",
        "                csv_df = csv_df[[q_col, a_col]].rename(columns={q_col: \"question\", a_col: \"answer\"})\n",
        "                self.df = pd.concat([self.df, csv_df], ignore_index=True)\n",
        "                print(f\"‚úÖ Knowledge Base: Augmented with {len(csv_df)} general tech support examples.\")\n",
        "            except FileNotFoundError:\n",
        "                print(f\"‚ö†Ô∏è General Training file '{csv_path}' not found.\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error loading CSV: {e}\")\n",
        "\n",
        "        # 3. Build Search Index\n",
        "        if not self.df.empty:\n",
        "            self.df['question'] = self.df['question'].fillna('')\n",
        "            self.df['answer'] = self.df['answer'].fillna('No detailed solution provided.')\n",
        "\n",
        "            self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "            self.tfidf_matrix = self.vectorizer.fit_transform(self.df['question'])\n",
        "        else:\n",
        "            print(\"‚ùå CRITICAL: Knowledge Base is empty. RAG will not work.\")\n",
        "            self.vectorizer = None\n",
        "\n",
        "    def search(self, query: str, top_k=2):\n",
        "        if self.vectorizer is None or self.df.empty:\n",
        "            return None\n",
        "\n",
        "        # Create vector for user query\n",
        "        query_vec = self.vectorizer.transform([query])\n",
        "\n",
        "        # Calculate similarity against ALL docs (JSON + CSV)\n",
        "        similarities = cosine_similarity(query_vec, self.tfidf_matrix).flatten()\n",
        "\n",
        "        # Threshold: matches below 0.15 are likely irrelevant noise\n",
        "        if np.max(similarities) < 0.15:\n",
        "            return None\n",
        "\n",
        "        top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            q_text = self.df.iloc[idx]['question']\n",
        "            a_text = self.df.iloc[idx]['answer']\n",
        "            results.append(f\"Q: {q_text}\\nA: {a_text}\")\n",
        "\n",
        "        return \"\\n---\\n\".join(results)"
      ],
      "metadata": {
        "id": "RP0mwYNZFZEo"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI CORE (NLU & Generation)"
      ],
      "metadata": {
        "id": "daan-SLGM_so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlu_service(message: str):\n",
        "    \"\"\"\n",
        "    Analyzes Intent + Sentiment + Profanity.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are the NLU module for CyberCare. Analyze this user message: \"{message}\"\n",
        "\n",
        "    Return a valid JSON object with keys:\n",
        "    - \"intent\": [\"technical\", \"billing\", \"account\", \"human_escalate\", \"greeting\"]\n",
        "    - \"confidence\": float (0.0 to 1.0)\n",
        "    - \"escalate_reason\": string (if escalating, explain why)\n",
        "\n",
        "    CRITICAL ESCALATION RULES (Set intent to \"human_escalate\"):\n",
        "    1. User explicitly asks for a human/agent.\n",
        "    2. User mentions \"lawsuit\", \"legal action\", \"fraud\", \"police\".\n",
        "    3. PROFANITY DETECTED: Any curse words or foul language.\n",
        "    4. ANGER/HOSTILITY: If the user seems frustrated, angry, or insults the bot (e.g., \"useless\", \"stupid\", \"ridiculous\").\n",
        "\n",
        "    Otherwise, categorize as technical/billing/account.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        text = response.text\n",
        "\n",
        "        # Smart JSON Extraction\n",
        "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
        "        if match:\n",
        "            return json.loads(match.group(0))\n",
        "        else:\n",
        "            raise ValueError(\"No JSON found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Fallback: Treat as technical so we try to answer it first\n",
        "        return {\"intent\": \"technical\", \"confidence\": 0.5, \"escalate_reason\": \"\"}\n",
        "\n",
        "def response_generator(user_text, nlu_data, context_docs, history_text):\n",
        "    system_prompt = f\"\"\"\n",
        "    You are CyberCare AI.\n",
        "\n",
        "    CONTEXT FROM DATABASE:\n",
        "    {context_docs if context_docs else \"No specific database match.\"}\n",
        "\n",
        "    USER INTENT: {nlu_data.get('intent')}\n",
        "    HISTORY: {history_text}\n",
        "    CURRENT MESSAGE: \"{user_text}\"\n",
        "\n",
        "    Instructions:\n",
        "    1. If 'CONTEXT FROM DATABASE' has a fix, USE IT and paraphrase politely.\n",
        "    2. If no context, provide general helpful advice.\n",
        "    3. Be concise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return model.generate_content(system_prompt).text\n",
        "    except:\n",
        "        return \"I am currently overloaded. Please try again in a moment.\""
      ],
      "metadata": {
        "id": "kTSeGOn4GEtI"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DIALOG MANAGER"
      ],
      "metadata": {
        "id": "0ibz2jEWNHxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DialogManager:\n",
        "    def __init__(self, db, kb, crm):\n",
        "        self.db = db\n",
        "        self.kb = kb\n",
        "        self.crm = crm\n",
        "\n",
        "    def process_message(self, user_id, convo_id, text):\n",
        "        # 1. Log User\n",
        "        self.db.log_message(convo_id, \"user\", text)\n",
        "\n",
        "        # 2. NLU\n",
        "        nlu = nlu_service(text)\n",
        "\n",
        "        # 3. Escalation Check\n",
        "        if nlu.get(\"intent\") == \"human_escalate\" or nlu.get(\"confidence\", 0) < 0.4:\n",
        "            ticket = self.crm.create_ticket(user_id, text, nlu.get(\"escalate_reason\"))\n",
        "            reply = f\"I've escalated this to a human agent. Ticket #{ticket}\"\n",
        "            self.db.log_message(convo_id, \"bot\", reply)\n",
        "            return reply\n",
        "\n",
        "        # 4. RAG Search\n",
        "        context = self.kb.search(text)\n",
        "\n",
        "        # 5. History\n",
        "        hist = \"\\n\".join([f\"{m['sender']}: {m['text']}\" for m in self.db.messages[-4:]])\n",
        "\n",
        "        # 6. Generate\n",
        "        reply = response_generator(text, nlu, context, hist)\n",
        "\n",
        "        # 7. Log Bot\n",
        "        self.db.log_message(convo_id, \"bot\", reply)\n",
        "        return reply"
      ],
      "metadata": {
        "id": "XP-D1xRzGO_j"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZATION & TESTING (The Simulation)"
      ],
      "metadata": {
        "id": "so7OoyK0NQDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize Components\n",
        "print(\"\\n--- üöÄ STARTING CYBERCARE SYSTEM (NORDVPN EDITION) ---\")\n",
        "db = MockDatabase()\n",
        "\n",
        "# LOAD BOTH DATASETS HERE\n",
        "# QnA.json = Specific Rules (Priority)\n",
        "# tech_support_dataset.csv = General Training (Fallback)\n",
        "kb = KnowledgeRetriever(json_path=\"QnA.json\", csv_path=\"tech_support_dataset.csv\")\n",
        "\n",
        "crm = MockCRM()\n",
        "bot = DialogManager(db, kb, crm)\n",
        "\n",
        "# 2. User Setup\n",
        "uid = db.create_user(\"customer@nordvpn.com\", \"VPN User\")\n",
        "cid = db.start_conversation(uid)\n",
        "\n",
        "print(f\"\\n‚úÖ Simulation Ready! Knowledge Base size: {len(kb.df)} entries.\")\n",
        "\n",
        "# 3. Test Loop\n",
        "# We mix specific NordVPN questions with generic tech support issues\n",
        "queries = [\n",
        "    \"I forgot my password\",             # Generic (exists in both, will likely pick JSON if query matches better)\n",
        "    \"How do I use Meshnet?\",            # Specific to NordVPN (JSON)\n",
        "    \"I want to cancel auto-renewal\",    # Specific to NordVPN (JSON)\n",
        "    \"My printer is not responding\",     # Generic Tech Support (CSV)\n",
        "    \"Can I watch Netflix?\",             # Specific to NordVPN (JSON)\n",
        "    \"You dirty clanker\"                # Escalation Trigger\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(f\"\\nüë§ User: {q}\")\n",
        "    ans = bot.process_message(uid, cid, q)\n",
        "    print(f\"ü§ñ Bot: {ans}\")"
      ],
      "metadata": {
        "id": "zeFkaxswJA0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "outputId": "e96e2986-2164-4c4d-8dbb-a5bd61a9129f"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üöÄ STARTING CYBERCARE SYSTEM (NORDVPN EDITION) ---\n",
            "‚úÖ Knowledge Base: Loaded 15 specific NordVPN rules from QnA.json.\n",
            "‚úÖ Knowledge Base: Augmented with 1896 general tech support examples.\n",
            "\n",
            "‚úÖ Simulation Ready! Knowledge Base size: 1911 entries.\n",
            "\n",
            "üë§ User: I forgot my password\n",
            "ü§ñ Bot: If you've forgotten your password, please look for a \"Forgot password\" or \"Reset password\" link on the login page. This will typically guide you through the recovery process.\n",
            "\n",
            "üë§ User: How do I use Meshnet?\n",
            "ü§ñ Bot: Meshnet allows you to access devices over encrypted private tunnels. To use it:\n",
            "\n",
            "1.  Turn on Meshnet in the NordVPN app on all devices you want to connect.\n",
            "2.  Link your devices by logging into the same Nord Account or sending an invitation to another user.\n",
            "3.  Use the assigned Nord name or IP address to access devices remotely.\n",
            "\n",
            "üë§ User: I want to cancel auto-renewal\n",
            "ü§ñ Bot: To cancel your auto-renewal:\n",
            "\n",
            "1.  Log in to your Nord Account.\n",
            "2.  Go to the Billing tab.\n",
            "3.  Click 'Cancel' next to Auto-renewal.\n",
            "4.  Select 'Cancel auto-renewal'.\n",
            "\n",
            "You'll receive a confirmation email once it's successfully turned off.\n",
            "\n",
            "üë§ User: My printer is not responding\n",
            "ü§ñ Bot: I'm sorry to hear your printer isn't responding. Please try running a system diagnostic tool to troubleshoot the issue.\n",
            "\n",
            "üë§ User: Can I watch Netflix?\n",
            "ü§ñ Bot: Yes, you can securely access streaming services like Netflix with NordVPN.\n",
            "\n",
            "To do so:\n",
            "1. Connect to a VPN server in the country where the content is available (e.g., a US server for US Netflix).\n",
            "2. Clear your browser cache or restart the streaming app.\n",
            "If you still have issues, try a different server city or contact support.\n",
            "\n",
            "üë§ User: You dirty clanker\n",
            "\n",
            "[üîå CRM] Escalating to Zendesk | User: 457062ea-72dd-4abe-abe2-21005bae34f6 | ID: TICKET-295D3F5A\n",
            "ü§ñ Bot: I've escalated this to a human agent. Ticket #TICKET-295D3F5A\n"
          ]
        }
      ]
    }
  ]
}